from __future__ import annotations
import time
from datetime import date, timedelta
from typing import List, Optional

import pandas as pd
import numpy as np
import requests

# ----------------------------
# CONFIGURATION
# ----------------------------
API_KEY = "vlno9xSDPNRVEARxO1WEZptEW2lKYU5I"  # ta cl√© Massive
XAU_TICKER = "C:XAUUSD"
UUP_VARIANTS: List[str] = ["UUP", "C:UUP", "U:UUP"]  # variantes possibles
TIMEFRAME_MINUTES = 15
DAYS_LOOKBACK = 14  # nombre de jours pour r√©cup√©rer l'historique
MIN_DATA_POINTS = 100  # seuil minimum pour corr√©lation
PRINT_JSON_RESPONSES = False  # True pour debug


# ----------------------------
# FONCTIONS UTILITAIRES
# ----------------------------
def build_massive_url(ticker: str, start_date: date, end_date: date, agg_minutes: int = 5) -> str:
    """Construit l'URL Massive API pour r√©cup√©rer les bougies d'agr√©gat M5."""
    base = "https://api.massive.com/v2/aggs/ticker"
    return (
        f"{base}/{ticker}/range/{agg_minutes}/minute/{start_date}/{end_date}"
        f"?adjusted=true&sort=asc&limit=1000000&apiKey={API_KEY}"
    )


def fetch_massive_agg_minute(ticker: str, start_date: date, end_date: date, agg_minutes: int = 5) -> Optional[pd.DataFrame]:
    """R√©cup√®re des bougies d'agr√©gat M5 depuis Massive API."""
    url = build_massive_url(ticker, start_date, end_date, agg_minutes)
    try:
        resp = requests.get(url, timeout=20)
        resp.raise_for_status()
        data = resp.json()
        if PRINT_JSON_RESPONSES:
            import json
            print(json.dumps(data, indent=2))

        candles = data.get("results") or []
        if not candles:
            print(f"‚ö†Ô∏è Aucune 'results' pour {ticker}.")
            return None

        df = pd.DataFrame(candles)
        df["t"] = pd.to_datetime(df["t"], unit="ms", utc=True)
        df = df.set_index("t")
        df = df.rename(columns={"o": "Open", "h": "High", "l": "Low", "c": "Close", "v": "Volume"})
        df = df[["Open", "High", "Low", "Close", "Volume"]].sort_index()
        return df
    except requests.exceptions.RequestException as exc:
        print(f"‚ùå Erreur requ√™te Massive pour {ticker} : {exc}")
        return None
    except ValueError as exc:
        print(f"‚ùå Erreur parsing JSON pour {ticker} : {exc}")
        return None


def try_fetch_variants(variants: List[str], start_date: date, end_date: date) -> Optional[tuple[str, pd.DataFrame]]:
    """Essaie chaque variante de ticker et retourne le premier DataFrame valide."""
    for tick in variants:
        print(f"-> Tentative r√©cup√©ration pour '{tick}' ...")
        df = fetch_massive_agg_minute(tick, start_date, end_date, agg_minutes=TIMEFRAME_MINUTES)
        if df is not None and not df.empty:
            print(f"‚úÖ Succ√®s avec ticker '{tick}' ({len(df)} points).")
            return tick, df
        time.sleep(0.5)  # pause courte entre tentatives
    return None


def calculate_logreturn_correlation(df1: pd.DataFrame, df2: pd.DataFrame, min_points: int = MIN_DATA_POINTS) -> Optional[float]:
    """Aligne les 'Close', calcule log returns et corr√©lation Pearson."""
    combined = pd.concat([df1["Close"], df2["Close"]], axis=1, keys=["XAU_Close", "UUP_Close"])
    combined = combined.dropna()
    if len(combined) < min_points:
        print(f"‚ö†Ô∏è Pas assez de points synchronis√©s : {len(combined)} (< {min_points})")
        return None
    combined["XAU_r"] = np.log(combined["XAU_Close"] / combined["XAU_Close"].shift(1))
    combined["UUP_r"] = np.log(combined["UUP_Close"] / combined["UUP_Close"].shift(1))
    combined = combined.dropna()
    return combined["XAU_r"].corr(combined["UUP_r"])


# ----------------------------
# INTERPR√âTATION AUTOMATIQUE
# ----------------------------
def interpret_correlation(rho: float) -> str:
    """Retourne interpr√©tation automatique pour trading GOLD/USD."""
    if rho <= -0.7:
        strength = "TR√àS FORTE corr√©lation n√©gative"
        behavior = (
            "‚Üí Gold et UUP √©voluent fortement en sens inverse.\n"
            "‚Üí UUP ‚Üë = GOLD ‚Üì\n"
            "‚Üí UUP ‚Üì = GOLD ‚Üë\n"
        )
        trading = "Contexte parfait : UUP comme indicateur leader du GOLD."
    elif -0.7 < rho <= -0.3:
        strength = "corr√©lation n√©gative MOD√âR√âE"
        behavior = (
            "‚Üí Relation inverse pr√©sente mais moins pr√©cise.\n"
            "‚Üí UUP ‚Üë = GOLD ‚Üì g√©n√©ralement.\n"
        )
        trading = "UUP utile mais n√©cessite confirmation via volumes ou price action."
    elif -0.3 < rho < 0.3:
        strength = "corr√©lation FAIBLE / NEUTRE"
        behavior = "‚Üí Gold et UUP ne r√©agissent pas l‚Äôun √† l‚Äôautre.\n"
        trading = "√âviter de baser un trade sur le dollar. Possible changement de r√©gime."
    elif 0.3 <= rho < 0.7:
        strength = "corr√©lation POSITIVE anormale"
        behavior = "‚Üí Gold et USD montent ou baissent ensemble.\n"
        trading = "Risque √©lev√© : relation USD ‚Üî Gold cass√©e."
    else:
        strength = "corr√©lation POSITIVE TR√àS FORTE üö®"
        behavior = "‚Üí R√©gime totalement invers√©.\n"
        trading = "Ne pas baser de strat√©gie sur UUP. Contexte instable."

    explanation = (
        f"\nüîé Interpr√©tation du r√©gime actuel\n"
        f"Corr√©lation = {rho:.4f} ‚Üí {strength}\n\n"
        f"üìâ Comportement attendu :\n{behavior}\n"
        f"üéØ Cons√©quence trading :\n{trading}\n"
    )
    return explanation


# ----------------------------
# POINT D'ENTR√âE
# ----------------------------
def main():
    print("--- Analyse corr√©lation XAUUSD vs UUP (M5) via Massive API ---")
    end_date = date.today() - timedelta(days=1)
    start_date = end_date - timedelta(days=DAYS_LOOKBACK)

    # R√©cup√©ration XAUUSD
    df_xau = fetch_massive_agg_minute(XAU_TICKER, start_date, end_date, agg_minutes=TIMEFRAME_MINUTES)
    if df_xau is None:
        print("‚ùå Impossible de r√©cup√©rer XAUUSD. Arr√™t.")
        return

    # R√©cup√©ration UUP (essaie variantes)
    res = try_fetch_variants(UUP_VARIANTS, start_date, end_date)
    if res is None:
        print("‚ùå Aucune variante UUP n'a retourn√© de donn√©es valides.")
        return
    used_ticker, df_uup = res

    print(f"-> Points XAU: {len(df_xau)}, Points UUP({used_ticker}): {len(df_uup)}")

    # Calcul corr√©lation
    rho = calculate_logreturn_correlation(df_xau, df_uup)
    if rho is None:
        print("‚ùå Corr√©lation non calcul√©e (donn√©es insuffisantes).")
        return

    # Affichage final et interpr√©tation
    print("\n" + "=" * 70)
    print(f"CORR√âLATION (log returns) XAUUSD vs UUP({used_ticker}) : {rho:.4f}")
    print(interpret_correlation(rho))
    print("=" * 70)


if __name__ == "__main__":
    main()